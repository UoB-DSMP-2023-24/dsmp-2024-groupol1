{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    %ls\n",
    "    %cd drive/MyDrive/dsmp-2024-groupol1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/vdjdb.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df[['gene','cdr3','v.segm','j.segm','species','mhc.a','mhc.b','mhc.class','antigen.epitope','antigen.species','vdjdb.score']]\n",
    " \n",
    "# Select all human data\n",
    "human_data = selected_features[(selected_features['species'] == 'HomoSapiens') & (selected_features['vdjdb.score'] > 0)]\n",
    "\n",
    "# Drop duplicate rows\n",
    "human_data = human_data.drop_duplicates()\n",
    "\n",
    "# Delete rows with null values\n",
    "human_data  = human_data.dropna()\n",
    "# Print all data\n",
    "human_data.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRB = human_data[human_data['gene'] =='TRB']\n",
    "# rename the columns for our beta chain matrix calculation\n",
    "beta_chains = TRB[['cdr3', 'v.segm', 'j.segm', 'antigen.epitope']]\n",
    "beta_chains.rename(columns={'cdr3':'cdr3_b_aa','v.segm':'v_b_gene', 'j.segm':'j_b_gene'}, inplace=True)\n",
    "beta_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tcrdist3\n",
    "!pip install umap-learn\n",
    "!pip install umap-learn[plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tcrdist.repertoire import TCRrep\n",
    "import umap\n",
    "import umap.plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_dist_and_umap(df: pd.DataFrame, \n",
    "                            chain: str, \n",
    "                            gene: str) -> pd.DataFrame:\n",
    "    \n",
    "  tr = TCRrep(cell_df = df,\n",
    "            organism = 'human',\n",
    "            chains = [chain],\n",
    "            db_file = 'alphabeta_gammadelta_db.tsv')\n",
    "\n",
    "  if chain == 'beta':\n",
    "    distance_matrix = pd.concat([pd.DataFrame(tr.pw_cdr3_b_aa), tr.clone_df[gene]], axis = 1)\n",
    "  elif chain == 'alpha':\n",
    "    distance_matrix = pd.concat([pd.DataFrame(tr.pw_cdr3_a_aa), tr.clone_df[gene]], axis = 1)\n",
    "\n",
    "  value_counts_antigen = distance_matrix[gene].value_counts()\n",
    "  top_10_value_counts = value_counts_antigen.nlargest(7)\n",
    "  distance_matrix_filtered = distance_matrix[distance_matrix[gene].isin(top_10_value_counts.index)]\n",
    "\n",
    "  distances_reduced = umap.UMAP(n_components = 2, n_neighbors = 100).fit(distance_matrix_filtered.iloc[:, :-1].values)\n",
    "\n",
    "  output_dir = 'visualisations'\n",
    "\n",
    "  f = umap.plot.points(distances_reduced, labels=distance_matrix_filtered[gene])\n",
    "  f.set_xlabel('UMAP Dimension 1', fontsize=10)\n",
    "  f.set_ylabel('UMAP Dimension 2', fontsize=10)\n",
    "  f.set_title(f'UMAP Visualization of {chain}', fontsize=12)\n",
    "\n",
    "  # Save the figure\n",
    "  if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "  f.get_figure().savefig(f'{output_dir}/{chain}_chain_umap.png')\n",
    "  return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dist_matrix = calculate_dist_and_umap(beta_chains, 'beta', 'antigen.epitope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same as above but for alpha chains\n",
    "TRA = human_data[human_data['gene'] =='TRA']\n",
    "alpha_chains = TRA[['cdr3', 'v.segm', 'j.segm', 'antigen.epitope']].copy()\n",
    "alpha_chains.rename(columns={'cdr3':'cdr3_a_aa','v.segm':'v_a_gene', 'j.segm':'j_a_gene'}, inplace=True)\n",
    "print(alpha_chains.columns)\n",
    "\n",
    "alpha_df = calculate_dist_and_umap(alpha_chains, 'alpha', 'antigen.epitope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name = 'wukevin/tcr-bert'\n",
    "\n",
    "model = BertModel.from_pretrained(model_name, add_pooling_layer=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import  Sequence, Any\n",
    "from math import floor\n",
    "\n",
    "PAD = \"$\"\n",
    "MASK = \".\"\n",
    "UNK = \"?\"\n",
    "SEP = \"|\"\n",
    "CLS = \"*\"\n",
    "\n",
    "def is_whitespaced(seq: str) -> bool:\n",
    "    tok = list(seq)\n",
    "    spaces = [t for t in tok if t.isspace()]\n",
    "    if len(spaces) == floor(len(seq) / 2):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_pretrained_bert_tokenizer(path: str):\n",
    "    \"\"\"Get the pretrained BERT tokenizer from given path\"\"\"\n",
    "    tok = BertTokenizer.from_pretrained(\n",
    "        path,\n",
    "        do_basic_tokenize=False,\n",
    "        do_lower_case=False,\n",
    "        tokenize_chinese_chars=False,\n",
    "        unk_token=UNK,\n",
    "        sep_token=SEP,\n",
    "        pad_token=PAD,\n",
    "        cls_token=CLS,\n",
    "        mask_token=MASK,\n",
    "        padding_side=\"right\",\n",
    "    )\n",
    "    return tok\n",
    "\n",
    "def chunkify(x: Sequence[Any], chunk_size: int = 128):\n",
    "    retval = [x[i : i + chunk_size] for i in range(0, len(x), chunk_size)]\n",
    "    return retval\n",
    "\n",
    "def insert_whitespace(seq: str) -> str:\n",
    "    return \" \".join(list(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name = 'wukevin/tcr-bert'\n",
    "\n",
    "model = BertModel.from_pretrained(model_name, add_pooling_layer=False).to(device)\n",
    "model_tokenizer = get_pretrained_bert_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = beta_chains['cdr3_b_aa'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "import numpy as np\n",
    "\n",
    "layers = [-1]\n",
    "\n",
    "seqs = [s if is_whitespaced(s) else insert_whitespace(s) for s in chains]\n",
    "\n",
    "chunks = chunkify(seqs, 1)\n",
    "chunks_pair = [None]\n",
    "chunks_zipped = list(zip_longest(chunks, chunks_pair))\n",
    "embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "      for seq_chunk in chunks_zipped:\n",
    "          encoded = model_tokenizer(\n",
    "              *seq_chunk, padding=\"max_length\", max_length=64, return_tensors=\"pt\"\n",
    "          )\n",
    "          # manually calculated mask lengths\n",
    "          # temp = [sum([len(p.split()) for p in pair]) + 3 for pair in zip(*seq_chunk)]\n",
    "          input_mask = encoded[\"attention_mask\"].numpy()\n",
    "          encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "          # encoded contains input attention mask of (batch, seq_len)\n",
    "          x = model.forward(**encoded, output_hidden_states=True, output_attentions=True)\n",
    "\n",
    "          for i in range(len(seq_chunk[0])):\n",
    "                e = []\n",
    "                for l in layers:\n",
    "                    # Select the l-th hidden layer for the i-th example\n",
    "                    h = (x.hidden_states[l][i].cpu().numpy().astype(np.float64))\n",
    "                    if seq_chunk[1] is None:\n",
    "                      seq_len = len(seq_chunk[0][i].split())\n",
    "                    seq_hidden = h[1 : 1 + seq_len]\n",
    "                    e.append(seq_hidden.mean(axis=0))\n",
    "\n",
    "                e = np.hstack(e)\n",
    "                assert len(e.shape) == 1\n",
    "                embeddings.append(e)\n",
    "\n",
    "if len(embeddings[0].shape) == 1:\n",
    "    embeddings = np.stack(embeddings)\n",
    "else:\n",
    "    embeddings = np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_chains.reset_index(inplace= True)\n",
    "embedding_df = pd.concat([pd.DataFrame(embeddings), beta_chains['antigen.epitope']], axis = 1)\n",
    "value_counts_antigen = embedding_df['antigen.epitope'].value_counts()\n",
    "top_10_value_counts = value_counts_antigen.nlargest(7)\n",
    "embedding_df_filtered = embedding_df[embedding_df['antigen.epitope'].isin(top_10_value_counts.index)]\n",
    "print(embedding_df_filtered.shape)\n",
    "distances_reduced = umap.UMAP(n_components = 2).fit(embedding_df_filtered.iloc[:, :-1].values)\n",
    "distances_reduced\n",
    "output_dir = 'visualisations'\n",
    "f = umap.plot.points(distances_reduced, labels=embedding_df_filtered['antigen.epitope'])\n",
    "f.set_xlabel('UMAP Dimension 1', fontsize=10)\n",
    "f.set_ylabel('UMAP Dimension 2', fontsize=10)\n",
    "f.set_title(f'Beta Chain by antigen specificity - Bert Embedding', fontsize=12)\n",
    "f.get_figure().savefig(f'{output_dir}/beta_chain_umap_bert.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances for paired alpha and beta pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get all the IDs for the TCRs (A & B pairs should have the same ID)\n",
    "_ids = human_data['complex.id']\n",
    "_ids\n",
    "\n",
    "list_to_combine = []\n",
    "checked_ids = []\n",
    "def process_row(row):\n",
    "    # check the complex id not already checked\n",
    "    if row['complex.id'] not in checked_ids:\n",
    "        # find matching rows\n",
    "        matched_rows = human_data[human_data['complex.id'] == row['complex.id']]\n",
    "        # should be two (some rows have only 1 match)\n",
    "        if len(matched_rows) == 2:\n",
    "            # get the tcra row\n",
    "            tra_row = matched_rows.iloc[0]\n",
    "            # get the tcrb row\n",
    "            trb_row = matched_rows.iloc[1]\n",
    "            # add to list as a combined row\n",
    "            list_to_combine.append({'tcr_id_a':tra_row['complex.id'], 'tcr_id_b':trb_row['complex.id'], \n",
    "                                    'cdr3_a_aa': tra_row['cdr3'], 'cdr3_b_aa': trb_row['cdr3'],\n",
    "                                    'v_b_gene' :trb_row['v.segm'],\n",
    "                                    'j_b_gene':trb_row['j.segm'],\n",
    "                                    'v_a_gene':tra_row['v.segm'],\n",
    "                                    'j_a_gene':tra_row['j.segm'],\n",
    "                                   })\n",
    "            # we've checked this id now, so we need to make sure we don't have to check it again.\n",
    "            checked_ids.append(row['complex.id'])\n",
    "human_data.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table representing paired tcr rows\n",
    "paired_table = pd.DataFrame(list_to_combine)\n",
    "paired_table\n",
    "\n",
    "# Get paired distances\n",
    "\n",
    "tr_paired = TCRrep(cell_df = paired_table, \n",
    "            organism = 'human', \n",
    "            chains = ['alpha','beta'], \n",
    "            db_file = 'alphabeta_gammadelta_db.tsv')\n",
    "\n",
    "# get alpha chain distance calculations for paired tcrs and print them.\n",
    "paired_matrix_alpha_chain = tr_paired.pw_alpha \n",
    "paired_alpha_distances = pd.DataFrame(paired_matrix_alpha_chain)\n",
    "paired_alpha_distances\n",
    "\n",
    "# get beta chain distance calculations for paired tcrs and print them.\n",
    "paired_matrix_beta_chain = tr_paired.pw_beta\n",
    "paired_beta_distances = pd.DataFrame(paired_matrix_beta_chain)\n",
    "paired_beta_distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
